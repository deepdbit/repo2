{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095f0481",
   "metadata": {},
   "source": [
    "## Retrieve Access Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd56b2",
   "metadata": {},
   "source": [
    "Using deployment url to make LLM calls\n",
    "\n",
    "First step is to retreive the token - we make use of the key json file content and extract the authorization url, client id, secret & api url.\n",
    "\n",
    "Post request is done to retreive the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6960f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "with open(\"irpa-r1208-hands-on-exercises-sk.json\", \"r\") as key_file:\n",
    "    svcKey = json.load(key_file)\n",
    "authUrl = svcKey[\"url\"]\n",
    "clientid = svcKey[\"clientid\"]\n",
    "clientsecret = svcKey[\"clientsecret\"]\n",
    "apiUrl = svcKey[\"serviceurls\"][\"AI_API_URL\"]\n",
    "\n",
    "# request token\n",
    "params = {\"grant_type\": \"client_credentials\" }\n",
    "resp = requests.post(f\"{authUrl}/oauth/token\",\n",
    "                    auth=(clientid, clientsecret),\n",
    "                    params=params)\n",
    "\n",
    "BtpLlmApiUrl = apiUrl\n",
    "BtpLlmAccessToken = resp.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996be23",
   "metadata": {},
   "source": [
    "Deployment url's are initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d68fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini-1.0-pro (OK)\n",
    "deploymentUrl_gemini_1_0 = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d74bdeb62e0aace3\"\n",
    "\n",
    "# gpt-35-turbo (OK)\n",
    "deploymentUrl_gpt35_turbo = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/db892a872898f277\"\n",
    "\n",
    "# text-embedding-ada-002 (OK)\n",
    "deploymentUrl_ada_002 = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d50d5c53990484d7\"\n",
    "\n",
    "# gpt-4o (OK)\n",
    "deploymentUrl_gpt_4o = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d02fb5127194087a\"\n",
    "\n",
    "# gemini-pro-vision, whisper\n",
    "deploymentUrl_cpit = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dc3567fb9fdc9729\"\n",
    "\n",
    "# meta--llama3-70b-instruct (OK)\n",
    "deploymentUrl_llama = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/ddcaf9eb805927da\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712ec43",
   "metadata": {},
   "source": [
    "## GPT-3.5-Turbo | GPT-4o\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#early-access-playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e1883",
   "metadata": {},
   "source": [
    "api endpoint is provided /chat/completions along with api-version\n",
    "\n",
    "form the header with resource_group_id as default, content as json & pass the access token received above\n",
    "\n",
    "payload defined with content as prompt input along with parameters (temperature, max_tokens etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the necessary variables\n",
    "deployment_url = deploymentUrl_gpt35_turbo + \"/chat/completions?api-version=2024-02-01\"\n",
    "resource_group_id = 'default'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}',\n",
    "}\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Provide me a brief on SAP S/4HANA public Cloud\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.0,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['choices'][0]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee43c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1b322",
   "metadata": {},
   "source": [
    "## text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the URL and headers\n",
    "url = f\"{deploymentUrl_ada_002}/embeddings?api-version=2023-05-15\"\n",
    "headers = {\n",
    "    'AI-Resource-Group': '<Resource Group Id>',\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}'\n",
    "}\n",
    "\n",
    "# Define the payload\n",
    "data = {\n",
    "    \"input\": \"What is SAP?\"\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0ea24",
   "metadata": {},
   "source": [
    "## Gemini 1.0 pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the URL and the token\n",
    "deployment_url = deploymentUrl_gemini_1_0 + \"/models/gemini-1.0-pro:generateContent\"\n",
    "resource_group_id = \"default\"\n",
    "\n",
    "\n",
    "# Set the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}'\n",
    "}\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": {\"text\": \"Hello!\"}\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": {\"text\": \"Argh! What brings ye to my ship?\"}\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": {\"text\": \"Tell me about SAP\"}\n",
    "        }\n",
    "    ],\n",
    "    \"safety_settings\": {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "        \"temperature\": 0.9,\n",
    "        \"topP\": 1,\n",
    "        \"candidateCount\": 1,\n",
    "        \"maxOutputTokens\": 2048\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b36762",
   "metadata": {},
   "source": [
    "## meta--llama3-70b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b648b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Set environment variables or replace with your actual values\n",
    "resource_group_id = 'default'\n",
    "\n",
    "url = f'{deploymentUrl_llama}/chat/completions'\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}'\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"meta--llama3-70b-instruct\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is SAP?\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cd5be",
   "metadata": {},
   "source": [
    "## gpt-4o Image Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94488461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the necessary variables\n",
    "deployment_url = deploymentUrl_gpt_4o + \"/chat/completions?api-version=2024-02-01\"\n",
    "resource_group_id = 'default'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}',\n",
    "}\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Whats in this image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9885a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Define the necessary variables\n",
    "deployment_url = deploymentUrl_gpt_4o + \"/chat/completions?api-version=2024-02-01\"\n",
    "resource_group_id = 'default'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}',\n",
    "}\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"graph.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Whats in this image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79dd4f4",
   "metadata": {},
   "source": [
    "## gemini-pro-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10809ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Define the necessary variables\n",
    "deployment_url = deploymentUrl_cpit + \"/v1/chat/completions\"\n",
    "resource_group_id = 'default'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}',\n",
    "}\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"graph.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"model\": \"gemini-pro-vision\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Whats in this image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474aaa20",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the necessary variables\n",
    "deployment_url = deploymentUrl_cpit + \"/v1/audio/transcriptions?api-version=2024-02-15-preview\"\n",
    "resource_group_id = 'default'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'AI-Resource-Group': resource_group_id,\n",
    "    'Authorization': f'Bearer {BtpLlmAccessToken}',\n",
    "}\n",
    "\n",
    "# Read the audio file\n",
    "audio_file_path = \"harvard.mp3\"\n",
    "with open(audio_file_path, 'rb') as f:\n",
    "    audio_data = f.read()\n",
    "\n",
    "# Define the files payload\n",
    "files = {\n",
    "    'file': ('harvard.mp3', audio_data, 'audio/wav')\n",
    "}\n",
    "\n",
    "# Define the data payload (if needed; adjust as necessary for Whisper API)\n",
    "data = {\n",
    "    'model': 'whisper',  # or specify the model version if different\n",
    "    'language': 'en'  # optional, specify language if known\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(deployment_url, headers=headers, data=data, files=files)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3834fc8",
   "metadata": {},
   "source": [
    "## Using generative-ai-hub-sdk & RAG with HANA Vector Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8a22e",
   "metadata": {},
   "source": [
    "\"HANA_VECTOR_USER\" - Administrator User (DBADMIN)\n",
    "\n",
    "\"HANA_VECTOR_PASS\" - Administrator Password provided during setup\n",
    "\n",
    "\"HANA_HOST_VECTOR\" - SQL Endpoint (remove :443 while copying from endpoint url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a13bb3",
   "metadata": {},
   "source": [
    "add the HANA DB & AI Core key information in the environment variable (can be done via json file entries / .env file, do not pass directly in code for your applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Define Keys HERE\n",
    "env_vars = {    \n",
    " \"HANA_VECTOR_USER\": \"DBADMIN\",\n",
    " \"HANA_VECTOR_PASS\": \"<>\",\n",
    " \"HANA_HOST_VECTOR\": \"<>\",\n",
    " \"AICORE_AUTH_URL\": authUrl,\n",
    " \"AICORE_CLIENT_ID\": clientid,\n",
    " \"AICORE_CLIENT_SECRET\": clientsecret,\n",
    " \"AICORE_RESOURCE_GROUP\": \"default\",\n",
    " \"AICORE_BASE_URL\": apiUrl\n",
    "}\n",
    "\n",
    "os.environ.update(env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed8dc7",
   "metadata": {},
   "source": [
    "## generative-ai-hub-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410193",
   "metadata": {},
   "source": [
    "## gpt-35-turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22e4b0",
   "metadata": {},
   "source": [
    "approach 1 - use chat from openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e966cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "messages = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Do other Azure Cognitive Services support this too?\"} ]\n",
    "\n",
    "kwargs = dict(model_name='gpt-35-turbo', messages=messages)\n",
    "response = chat.completions.create(**kwargs)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c8fd15",
   "metadata": {},
   "source": [
    "## gpt-35-turbo | gpt-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7f6b9",
   "metadata": {},
   "source": [
    "approach 2 - use ChatOpenAI from langchain.openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "\n",
    "proxy_client=get_proxy_client('gen-ai-hub')\n",
    "chat_llm = ChatOpenAI(proxy_model_name = 'gpt-4o', proxy_client = proxy_client, temperature=0.0)\n",
    "\n",
    "response = chat_llm.invoke(\"who is the CEO of SAP?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "\n",
    "proxy_client=get_proxy_client('gen-ai-hub')\n",
    "chat_llm = ChatOpenAI(proxy_model_name = 'gpt-4o', proxy_client = proxy_client, temperature=0.0)\n",
    "\n",
    "response = chat_llm.invoke(\"What is the Cataract surgery policy in SAP?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58b745",
   "metadata": {},
   "source": [
    "## text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "response = embeddings.create(\n",
    "    input=\"Every decoding is another encoding.\",\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91652a3a",
   "metadata": {},
   "source": [
    "## gemini-1.0-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.google.clients import GenerativeModel\n",
    "\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "kwargs = dict({'model_name': 'gemini-1.0-pro'})\n",
    "model = GenerativeModel(proxy_client=proxy_client, **kwargs)\n",
    "content = [{\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": [{\n",
    "        \"text\": \"Write a story about a magic backpack.\"\n",
    "    }]\n",
    "}]\n",
    "model_response = model.generate_content(content)\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72834fd0",
   "metadata": {},
   "source": [
    "## meta--llama3-70b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ce298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import completions\n",
    "\n",
    "response = completions.create(\n",
    "  model_name=\"meta--llama3-70b-instruct\",\n",
    "  prompt=\"What is SAP?\",\n",
    "  max_tokens=70,\n",
    "  temperature=0\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dccaa",
   "metadata": {},
   "source": [
    "## RAG with HANA Vector Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09aa13",
   "metadata": {},
   "source": [
    "use pip install hdbcli & pip install hana_ml to import these libraries (or pip3 install..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798130c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dbapi from hdbcli library\n",
    "from hdbcli import dbapi\n",
    "import hana_ml.dataframe as dataframe\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from langchain.chains import RetrievalQA # deprecated\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores.hanavector import HanaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec01905",
   "metadata": {},
   "source": [
    "The below code retrieves the values of HANA user, Password & Host from environment variables. You can directly pass the same as well instead of first adding to the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe140a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HANA Cloud username from environment variables\n",
    "HANA_USER_VDB = os.getenv('HANA_VECTOR_USER')\n",
    "# Get the HANA Cloud password from environment variables\n",
    "HANA_PASSWORD_VDB = os.getenv('HANA_VECTOR_PASS')\n",
    "# Get the HANA Cloud host from environment variables\n",
    "HANA_HOST  = os.getenv('HANA_HOST_VECTOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3daf24c",
   "metadata": {},
   "source": [
    "Establish the connection to HANA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4df78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use connection settings from the environment\n",
    "connection = dbapi.connect(\n",
    "    address=HANA_HOST,\n",
    "    port=443,\n",
    "    user=HANA_USER_VDB,\n",
    "    password=HANA_PASSWORD_VDB,\n",
    "    encrypt='true',\n",
    "    autocommit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection Context\n",
    "conn = dataframe.ConnectionContext(\n",
    "    address=HANA_HOST,  \n",
    "    port=443,\n",
    "    user=HANA_USER_VDB,\n",
    "    password=HANA_PASSWORD_VDB,\n",
    "    encrypt='true',\n",
    "    autocommit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67edd9",
   "metadata": {},
   "source": [
    "Import necessary langchain modules along with assignment of the proxy client as gen-ai-hub & chat_llm model initiation as gpt-35-turbo, which can be changed based on model availability in GENAI Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "chat_llm = ChatOpenAI(proxy_model_name='gpt-35-turbo', proxy_client=proxy_client, temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b17290",
   "metadata": {},
   "source": [
    "This code performs the document split (loaded using PyPDF Loader available with Langchain) in chunks of size 200 & chunk overlap 25. If you wish to use a text file, you can use TextLoader added as import below (for other file types supported, refer - https://python.langchain.com/docs/modules/data_connection/document_loaders/)\n",
    "\n",
    "split of the text is done and embedding model is initiated using text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the PDF file & Create Chunks\n",
    "loader = PyPDFLoader('./India Medical Insurance Policy 2024.pdf')\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=200, chunk_overlap=25)\n",
    "\n",
    "#pages = loader.load_and_split(text_splitter)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d394f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = HanaDB(\n",
    "    embedding=embedding_model, connection=connection, table_name=\"INSURANCE\"\n",
    ")\n",
    "\n",
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe24833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the table\n",
    "hdf = conn.sql(''' SELECT \"VEC_TEXT\", \"VEC_META\", TO_NVARCHAR(\"VEC_VECTOR\") AS \"VEC_VECTOR\" FROM \"INSURANCE\" ''')\n",
    "df = hdf.head(10).collect()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d9f31",
   "metadata": {},
   "source": [
    "RetrieverQA is deprecated. the new approach is to use create_retreival_chain\n",
    "\n",
    "first initiate the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4587b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Provide answers based on context provided:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076b430",
   "metadata": {},
   "source": [
    "create document_chain with chat_llm (defined earlier and prompt\n",
    "\n",
    "retrieval chain using hana db & document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat_llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1c4d1",
   "metadata": {},
   "source": [
    "invoke the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"what is the insurance cap?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab409853",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"what is the cataract surgery policy?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae922e",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "https://python.langchain.com/docs/integrations/vectorstores/sap_hanavector/\n",
    "\n",
    "https://github.tools.sap/Artificial-Intelligence-CoE/ies-genai-platform-models-cookbook/tree/main/examples/python/SAP-HANA-Cloud-VectorEngine-PoC\n",
    "\n",
    "https://github.wdf.sap.corp/hana-multi-model/vector-getting-started\n",
    "\n",
    "https://discovery-center.cloud.sap/protected/index.html#/mymissiondetail/95888/card/10571818/?tab=projectboard\n",
    "\n",
    "generative-ai-hub-sdk code source - https://github.wdf.sap.corp/AI/generative-ai-hub-sdk/blob/main/docs/gen_ai_hub/examples/gen_ai_hub.ipynb\n",
    "\n",
    "LLM endpoints - https://pages.github.tools.sap/Artificial-Intelligence-CoE/ies-genai-platform-models-cookbook/general/api-calls/inference-endpoints/\n",
    "\n",
    "genaihub llm postman collections - https://github.tools.sap/Artificial-Intelligence-CoE/ies-genai-platform-models-cookbook/blob/8d6748546931457171edfacc09cf9dcaa0e046a8/examples/postman/GenAI-Hub-LLM-Deployments-postman-collection.json\n",
    "\n",
    "OpenAI API versions - https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b527d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
